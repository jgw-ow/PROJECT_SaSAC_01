{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def get_news_articles(base_url, year, max_articles=1000):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.5481.177 Safari/537.36',\n",
    "        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'Referer': 'https://www.naver.com/'\n",
    "    }\n",
    "    articles = []\n",
    "    page = 1\n",
    "    pbar = tqdm(total=max_articles, desc=f\"Processing Articles for {year}\")  # 연도별 진행 바 생성\n",
    "    while len(articles) < max_articles:\n",
    "        url = f\"{base_url}&nso=so:dd,p:from{year}0101to{year}1231&start={(page - 1) * 10}\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        news_items = soup.select(\".news_area\")  # 기사 영역 선택자\n",
    "        if not news_items:  # 기사가 더 이상 없으면 종료\n",
    "            print(\"No more articles found or invalid selector.\")\n",
    "            break\n",
    "        for item in news_items:\n",
    "            title_elem = item.select_one(\"a.news_tit\")  # 제목 선택\n",
    "            press_elem = item.select_one(\"a.info.press\")  # 언론사 선택\n",
    "            desc_elem = item.select_one(\".dsc_txt_wrap\")  # 본문 요약 선택\n",
    "            \n",
    "            title = title_elem.text.strip() if title_elem else \"No Title\"\n",
    "            link = title_elem['href'] if title_elem else None\n",
    "            press = press_elem.text.strip() if press_elem else \"No Press\"\n",
    "            description = desc_elem.text.strip() if desc_elem else \"No Description\"\n",
    "            \n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"link\": link,\n",
    "                \"press\": press,\n",
    "                \"description\": description\n",
    "            })\n",
    "            pbar.update(1)  # 진행 바 업데이트\n",
    "            if len(articles) >= max_articles:\n",
    "                break\n",
    "        page += 1\n",
    "        time.sleep(3)  # 요청 간 대기 시간 증가\n",
    "    pbar.close()  # 진행 바 종료\n",
    "    return articles\n",
    "\n",
    "def save_articles_to_file(articles, year):\n",
    "    filename = f\"articles_{year}.csv\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Title,Link,Press,Description\\n\")\n",
    "        for article in articles:\n",
    "            file.write(f'\"{article[\"title\"]}\",\"{article[\"link\"]}\",\"{article[\"press\"]}\",\"{article[\"description\"]}\"\\n')\n",
    "    print(f\"Saved {len(articles)} articles to {filename}\")\n",
    "\n",
    "# 네이버 뉴스 검색 기본 URL\n",
    "base_url = \"https://search.naver.com/search.naver?where=news&query=%EC%84%B1%EC%88%98+%ED%8C%9D%EC%97%85%EC%8A%A4%ED%86%A0%EC%96%B4\"\n",
    "\n",
    "# 연도별 크롤링 수행\n",
    "years = range(2020, 2025)  # 2020년부터 2025년까지\n",
    "max_articles = 1000        # 연도별 최대 기사 수\n",
    "\n",
    "for year in years:\n",
    "    articles = get_news_articles(base_url, year, max_articles=max_articles)\n",
    "    if articles:\n",
    "        save_articles_to_file(articles, year)\n",
    "    else:\n",
    "        print(f\"No articles were collected for {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def get_news_articles(base_url, keywords, year, max_articles=1000):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.5481.177 Safari/537.36',\n",
    "        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'Referer': 'https://www.naver.com/'\n",
    "    }\n",
    "    articles = []\n",
    "    page = 1\n",
    "    keyword_query = '+'.join(keywords)  # 키워드를 '+'로 연결하여 검색 쿼리 생성\n",
    "    pbar = tqdm(total=max_articles, desc=f\"Processing Articles for {year} - {' '.join(keywords)}\")  # 연도별 진행 바 생성\n",
    "    while len(articles) < max_articles:\n",
    "        url = f\"{base_url}&query={keyword_query}&nso=so:dd,p:from{year}0101to{year}1231&start={(page - 1) * 10}\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        news_items = soup.select(\".news_area\")  # 기사 영역 선택자\n",
    "        if not news_items:  # 기사가 더 이상 없으면 종료\n",
    "            print(\"No more articles found or invalid selector.\")\n",
    "            break\n",
    "        for item in news_items:\n",
    "            title_elem = item.select_one(\"a.news_tit\")  # 제목 선택\n",
    "            press_elem = item.select_one(\"a.info.press\")  # 언론사 선택\n",
    "            desc_elem = item.select_one(\".dsc_txt_wrap\")  # 본문 요약 선택\n",
    "            \n",
    "            title = title_elem.text.strip() if title_elem else \"No Title\"\n",
    "            link = title_elem['href'] if title_elem else None\n",
    "            press = press_elem.text.strip() if press_elem else \"No Press\"\n",
    "            description = desc_elem.text.strip() if desc_elem else \"No Description\"\n",
    "            \n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"link\": link,\n",
    "                \"press\": press,\n",
    "                \"description\": description\n",
    "            })\n",
    "            pbar.update(1)  # 진행 바 업데이트\n",
    "            if len(articles) >= max_articles:\n",
    "                break\n",
    "        page += 1\n",
    "        time.sleep(3)  # 요청 간 대기 시간 증가\n",
    "    pbar.close()  # 진행 바 종료\n",
    "    return articles\n",
    "\n",
    "def save_articles_to_file(articles, year, keywords):\n",
    "    keyword_str = '_'.join(keywords)\n",
    "    filename = f\"articles_{keyword_str}_{year}.csv\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Title,Link,Press,Description\\n\")\n",
    "        for article in articles:\n",
    "            file.write(f'\"{article[\"title\"]}\",\"{article[\"link\"]}\",\"{article[\"press\"]}\",\"{article[\"description\"]}\"\\n')\n",
    "    print(f\"Saved {len(articles)} articles to {filename}\")\n",
    "\n",
    "# 사용자로부터 키워드 입력받기\n",
    "keywords = input(\"검색할 키워드를 입력해주세요 (쉼표로 구분): \")\n",
    "keyword_list = [keyword.strip() for keyword in keywords.split(',')]\n",
    "\n",
    "# 네이버 뉴스 검색 기본 URL\n",
    "base_url = \"https://search.naver.com/search.naver?where=news\"\n",
    "\n",
    "# 연도별 크롤링 수행\n",
    "years = range(2020, 2025)  # 2020년부터 2025년까지\n",
    "max_articles = 1000        # 연도별 최대 기사 수\n",
    "\n",
    "for year in years:\n",
    "    articles = get_news_articles(base_url, keyword_list, year, max_articles=max_articles)\n",
    "    if articles:\n",
    "        save_articles_to_file(articles, year, keyword_list)\n",
    "    else:\n",
    "        print(f\"No articles were collected for {year} with keywords '{', '.join(keyword_list)}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
